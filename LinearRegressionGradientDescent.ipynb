{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "\n",
    "def compute_error_for_given_points(b, m, points):\n",
    "    ## Error = 1/N Sigma(N, from i=1)(yi - (mxi + b))^2\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)):\n",
    "        ##y starts from 1???\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        totalError += (y - (m * x + b)) **2\n",
    "    return totalError / float(len(points))\n",
    "\n",
    "\n",
    "def step_gradient(b_current, m_current, points, learning_rate):\n",
    "    ##gradient descent\n",
    "    ## partial derivative of m and b\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        b_gradient += -(2/N) * (y - (m_current * x) + (b_current))\n",
    "        m_gradient += -(2/N) * x * (y - (m_current * x) + (b_current))\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "    return [new_b, new_m]\n",
    "\n",
    "\n",
    "def gradient_descent_runner(points, starting_b, starting_m, learning_rate, num_iterations):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        ## what is that b, m = ???\n",
    "        [b, m] = step_gradient(b, m, array(points), learning_rate)\n",
    "    return [b, m]\n",
    "\n",
    "\n",
    "def run():\n",
    "    ##genfromtext is from numpy\n",
    "    ##check the function genfromtext\n",
    "    points = genfromtxt('data for Linear Regression Gradient Descent.csv', delimiter=',')\n",
    "    \n",
    "    ##learning rate is a hyper parameter\n",
    "    learning_rate=0.0001\n",
    "    \n",
    "    ##y = mx+b (slop formula)\n",
    "    initial_b = 0\n",
    "    initial_m = 0\n",
    "    num_iterations = 1000\n",
    "    ##gradient_descent_runner\n",
    "    [b, m] = gradient_descent_runner(points, initial_b, initial_m, learning_rate, num_iterations)\n",
    "    print(b)\n",
    "    print(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0898988922179\n",
      "1.48125422637\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
